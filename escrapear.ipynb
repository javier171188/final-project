{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feedparser\n",
    "#!pip install beautifulsoup4\n",
    "#!pip install bs4\n",
    "#!pip install lxml\n",
    "#!pip install pandas\n",
    "#!pip install umap\n",
    "#!pip install 'umap-learn==0.3.10'\n",
    "#!pip install requests\n",
    "#!pip install nltk\n",
    "#!pip install umap\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('venv/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "#import umap.umap_ as UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpieza\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = feedparser.parse('http://rss.cnn.com/rss/edition.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_parser():\n",
    "    CNN_list=[]\n",
    "    CNN_URLS = {\n",
    "    \"Top Stories\": \"http://rss.cnn.com/rss/edition.rss\",\n",
    "    \"World\": \"http://rss.cnn.com/rss/edition_world.rss\",\n",
    "    \"Africa\": \"http://rss.cnn.com/rss/edition_africa.rss\",\n",
    "    \"Americas\": \"http://rss.cnn.com/rss/edition_americas.rss\",\n",
    "    \"Asia\": \"http://rss.cnn.com/rss/edition_asia.rss\",\n",
    "    \"Europe\": \"http://rss.cnn.com/rss/edition_europe.rss\",\n",
    "    \"Middle East\": \"http://rss.cnn.com/rss/edition_meast.rss\",\n",
    "    \"U.S.\": \"http://rss.cnn.com/rss/edition_us.rss\",\n",
    "    \"Money\": \"http://rss.cnn.com/rss/money_news_international.rss\",\n",
    "    \"Technology\": \"http://rss.cnn.com/rss/edition_technology.rss\",\n",
    "    \"Science & Space\": \"http://rss.cnn.com/rss/edition_space.rss\",\n",
    "    \"Entertainment\":\"http://rss.cnn.com/rss/edition_entertainment.rss\",\n",
    "    \"World Sport\":\"http://rss.cnn.com/rss/edition_sport.rss\",\n",
    "    \"Football\" : \"http://rss.cnn.com/rss/edition_football.rss\",\n",
    "    \"Golf\": \"http://rss.cnn.com/rss/edition_golf.rss\",\n",
    "    \"Motorsport\": \"http://rss.cnn.com/rss/edition_motorsport.rss\",\n",
    "    \"Tennis\": \"http://rss.cnn.com/rss/edition_tennis.rss\",\n",
    "    \"Travel\":\"http://rss.cnn.com/rss/edition_travel.rss\",\n",
    "    \"Video\":\"http://rss.cnn.com/rss/cnn_freevideo.rss\",\n",
    "    \"Most Recent\":\"http://rss.cnn.com/rss/cnn_latest.rss\"}\n",
    "    for e in CNN_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(CNN_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            CNN_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return CNN_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_list = CNN_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOX_parser():\n",
    "    FOX_list = []\n",
    "    FOX_URLS = {'Fox':\"https://www.foxnews.com/about/rss\"}\n",
    "    \n",
    "    \n",
    "    for e in FOX_URLS:\n",
    "        if hasattr(ssl, '_create_unverified_context'):\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(FOX_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            FOX_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return FOX_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOX_list=FOX_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOX_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WSJ_parser():\n",
    "    WSJ_list=[]\n",
    "    WSJ_URLS = {\n",
    "    \"World\": \"https://feeds.a.dj.com/rss/RSSWorldNews.xml\",\n",
    "    \"Opinion\": \"https://feeds.a.dj.com/rss/RSSOpinion.xml\",\n",
    "    \"Business\":\"https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml\",\n",
    "    \"Markets\":\"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",\n",
    "    \"Technology\":\"https://feeds.a.dj.com/rss/RSSWSJD.xml\",\n",
    "    \"Lifestyle\":\"https://feeds.a.dj.com/rss/RSSLifestyle.xml\"}\n",
    "    for e in WSJ_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(WSJ_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            WSJ_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return WSJ_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_list = WSJ_parser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBC_parser():\n",
    "    BBC_list=[]\n",
    "    BBC_URLS = {\n",
    "    \"World\":\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "    \"UK\":\"http://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
    "    \"Business\":\"http://feeds.bbci.co.uk/news/business/rss.xml\",\n",
    "    \"Politics\": \"http://feeds.bbci.co.uk/news/politics/rss.xml\",\n",
    "    \"Health\": \"http://feeds.bbci.co.uk/news/health/rss.xml\",\n",
    "    \"Education\": \"http://feeds.bbci.co.uk/news/education/rss.xml\",\n",
    "    \"Science\": \"http://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
    "    \"Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
    "    \"Entretainment & Arts\": \"http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\"}\n",
    "    for e in BBC_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(BBC_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            BBC_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return BBC_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_list = BBC_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def USAT_parser():\n",
    "    USAT_list=[]\n",
    "    USAT_URLS = {\n",
    "    \"US\":\"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "    \"World\":\"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "    \"Opinion\":\"http://rssfeeds.usatoday.com/News-Opinion\",\n",
    "    \"Sports\":\"http://rssfeeds.usatoday.com/UsatodaycomSports-TopStories\",\n",
    "    \"Lifestyle\":\"http://rssfeeds.usatoday.com/usatoday-LifeTopStories\",\n",
    "    \"Money\":\"http://rssfeeds.usatoday.com/UsatodaycomMoney-TopStories\",\n",
    "    \"Tech\":\"http://rssfeeds.usatoday.com/usatoday-TechTopStories\",\n",
    "    \"Travel\":\"http://rssfeeds.usatoday.com/UsatodaycomTravel-TopStories\"}\n",
    "    for e in USAT_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(USAT_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            USAT_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return USAT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAT_list = USAT_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NYT_parser():\n",
    "    NYT_list=[]\n",
    "    NYT_URLS = {\n",
    "    \"World\":\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "    \"Politics\":\"https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml\",\n",
    "    \"Business\":\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\",\n",
    "    \"Technology\":\"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
    "    \"Sports\":\"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\"}\n",
    "    \n",
    "    for e in NYT_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(NYT_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            NYT_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return NYT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_list =NYT_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "News = CNN_list + FOX_list+WSJ_list+BBC_list+USAT_list+NYT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf = pd.DataFrame(News, columns = ['Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian military deployed and internet shut dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India passes controversial citizenship bill th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pence's lawyer rejects request to declassify U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McConnell will move to acquit Trump, senators say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump again mocks teen climate activist Greta ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles\n",
       "0  Indian military deployed and internet shut dow...\n",
       "1  India passes controversial citizenship bill th...\n",
       "2  Pence's lawyer rejects request to declassify U...\n",
       "3  McConnell will move to acquit Trump, senators say\n",
       "4  Trump again mocks teen climate activist Greta ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(s):\n",
    "    n = analyzer.polarity_scores(s)['neg']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Negative'] = Newsdf['Titles'].apply(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neut(s):\n",
    "    n = analyzer.polarity_scores(s)['neg']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Neutral'] = Newsdf['Titles'].apply(neut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(s):\n",
    "    n = analyzer.polarity_scores(s)['pos']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Positive'] = Newsdf['Titles'].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com(s):\n",
    "    n = analyzer.polarity_scores(s)['compound']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['compound'] = Newsdf['Titles'].apply(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Newsdf['token'] = Newsdf['Titles'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=English()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    tokens=parser(sentence)\n",
    "    \n",
    "    filtered_tokens=[]\n",
    "    for word in tokens:\n",
    "        lemma=word.lemma_.lower().strip()\n",
    "        #print (word, lemma)\n",
    "        if lemma not in STOP_WORDS and re.search('^[a-zA-Z]+$', lemma):\n",
    "            filtered_tokens.append(lemma)\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix=tfidf.fit_transform(Newsdf['Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=tfidf.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=1-cosine_similarity(tfidf_matrix)\n",
    "#prueba = dist[0:98,0:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan=HDBSCAN()\n",
    "clusters=hdbscan.fit_predict(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1315"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_clust = len(Newsdf.clusters.unique())\n",
    "numb_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(), columns=terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abiy</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abu</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abusing</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>...</th>\n",
       "      <th>yuri</th>\n",
       "      <th>zaha</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimbabweans</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1225 rows × 3775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandoned  abdul  abiy  able  aboard  abortions  abu  abuse  abusing  \\\n",
       "0           0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "1           0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "2           0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "3           0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "5           0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "...         ...    ...   ...   ...     ...        ...  ...    ...      ...   \n",
       "1310        0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "1311        0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "1312        0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "1313        0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "1314        0.0    0.0   0.0   0.0     0.0        0.0  0.0    0.0      0.0   \n",
       "\n",
       "      accelerating  ...  yuri  zaha  zealand  zimbabwe  zimbabweans  zoe  \\\n",
       "0              0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "1              0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "2              0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "3              0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "5              0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "...            ...  ...   ...   ...      ...       ...          ...  ...   \n",
       "1310           0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "1311           0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "1312           0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "1313           0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "1314           0.0  ...   0.0   0.0      0.0       0.0          0.0  0.0   \n",
       "\n",
       "      zombie  zoo  zoos  zuckerberg  \n",
       "0        0.0  0.0   0.0         0.0  \n",
       "1        0.0  0.0   0.0         0.0  \n",
       "2        0.0  0.0   0.0         0.0  \n",
       "3        0.0  0.0   0.0         0.0  \n",
       "5        0.0  0.0   0.0         0.0  \n",
       "...      ...  ...   ...         ...  \n",
       "1310     0.0  0.0   0.0         0.0  \n",
       "1311     0.0  0.0   0.0         0.0  \n",
       "1312     0.0  0.0   0.0         0.0  \n",
       "1313     0.0  0.0   0.0         0.0  \n",
       "1314     0.0  0.0   0.0         0.0  \n",
       "\n",
       "[1225 rows x 3775 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df[clusters==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polls       2.518152\n",
       "head        2.518152\n",
       "voters      2.161770\n",
       "uk          2.006255\n",
       "election    1.718793\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_cluster=tfidf_df[clusters==3].T.sum(axis=1).sort_values(ascending=False)\n",
    "top_words_cluster.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice = top_words_cluster.keys()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lewis"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(practice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3ba7ca468fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpractice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mnouns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "adjectives = []\n",
    "for token in practice:\n",
    "    pass\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == 'ADJ':\n",
    "        adjectives.append(token)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[6, 9, 12]\n",
      "We\n",
      "the geometry of the edges of the images\n",
      "We\n",
      "geometry\n",
      "the edges of the images\n",
      "We\n",
      "geometry\n",
      "edges\n",
      "the images\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"We try to explicitly describe the geometry of the edges of the images.\")\n",
    "\n",
    "for np in doc.noun_chunks: # use np instead of np.text\n",
    "    #print(np)\n",
    "    pass\n",
    "\n",
    "print()\n",
    "\n",
    "# code to recursively combine nouns\n",
    "# 'We' is actually a pronoun but included in your question\n",
    "# hence the token.pos_ == \"PRON\" part in the last if statement\n",
    "# suggest you extract PRON separately like the noun-chunks above\n",
    "\n",
    "index = 0\n",
    "nounIndices = []\n",
    "for token in doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nounIndices.append(index)\n",
    "        print()\n",
    "    index = index + 1\n",
    "\n",
    "\n",
    "print(nounIndices)\n",
    "for idxValue in nounIndices:\n",
    "    doc = nlp(\"We try to explicitly describe the geometry of the edges of the images.\")\n",
    "    span = doc[doc[idxValue].left_edge.i : doc[idxValue].right_edge.i+1]\n",
    "    span.merge()\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj' or token.dep_ == 'pobj' or token.pos_ == \"PRON\":\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian military deployed and internet shut dow...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India passes controversial citizenship bill th...</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pence's lawyer rejects request to declassify U...</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McConnell will move to acquit Trump, senators say</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump again mocks teen climate activist Greta ...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Some N.B.A. Draft-Night Snubs Are Turning Into...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>The Knicks Can’t Fix It</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Stars Dismiss Coach Jim Montgomery for ‘Unprof...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>For UConn, a Transition Year to the Big East H...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Eli Manning Returns but Giants Lose to Eagles</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5499</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1315 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titles  Negative  Neutral  \\\n",
       "0     Indian military deployed and internet shut dow...     0.333    0.333   \n",
       "1     India passes controversial citizenship bill th...     0.205    0.205   \n",
       "2     Pence's lawyer rejects request to declassify U...     0.314    0.314   \n",
       "3     McConnell will move to acquit Trump, senators say     0.000    0.000   \n",
       "4     Trump again mocks teen climate activist Greta ...     0.300    0.300   \n",
       "...                                                 ...       ...      ...   \n",
       "1310  Some N.B.A. Draft-Night Snubs Are Turning Into...     0.307    0.307   \n",
       "1311                            The Knicks Can’t Fix It     0.000    0.000   \n",
       "1312  Stars Dismiss Coach Jim Montgomery for ‘Unprof...     0.000    0.000   \n",
       "1313  For UConn, a Transition Year to the Big East H...     0.000    0.000   \n",
       "1314      Eli Manning Returns but Giants Lose to Eagles     0.336    0.336   \n",
       "\n",
       "      Positive  compound  clusters  \n",
       "0        0.000   -0.6705        -1  \n",
       "1        0.000   -0.2023        -1  \n",
       "2        0.000   -0.4939        -1  \n",
       "3        0.205    0.2023        -1  \n",
       "4        0.000   -0.4588         4  \n",
       "...        ...       ...       ...  \n",
       "1310     0.000   -0.4767        -1  \n",
       "1311     0.000    0.0000        -1  \n",
       "1312     0.000    0.0000        -1  \n",
       "1313     0.224    0.3818        -1  \n",
       "1314     0.000   -0.5499        -1  \n",
       "\n",
       "[1315 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['cluster0-shard-00-00-tmwuw.mongodb.net:27017', 'cluster0-shard-00-02-tmwuw.mongodb.net:27017', 'cluster0-shard-00-01-tmwuw.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='Cluster0-shard-0', ssl=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import datetime module\n",
    "import datetime\n",
    "# import pymongo module\n",
    "import pymongo\n",
    "#import dns\n",
    "# connection string\n",
    "client = pymongo.MongoClient(\"mongodb+srv://uaqro:Croqueta1.@cluster0-tmwuw.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "db  =client.news_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['cluster0-shard-00-00-tmwuw.mongodb.net:27017', 'cluster0-shard-00-02-tmwuw.mongodb.net:27017', 'cluster0-shard-00-01-tmwuw.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='Cluster0-shard-0', ssl=True), 'news_clusters'), 'news')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colec = db.news\n",
    "colec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f27558b0888>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentos = {\"_id\":75,\"company\":\"Capital One\",\n",
    "\"city\":\"McLean\",\n",
    "\"state\":\"VA\",\n",
    "\"country\":\"USA\"}\n",
    "# insert document into collection\n",
    "idennt = colec.insert_one(documentos)\n",
    "idennt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####De aquí para abajo es el código de uaqro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_parser():\n",
    "    CNN_URLS = {\n",
    "    \"Top Stories\": \"http://rss.cnn.com/rss/edition.rss\",\n",
    "    \"World\": \"http://rss.cnn.com/rss/edition_world.rss\",\n",
    "    \"Africa\": \"http://rss.cnn.com/rss/edition_africa.rss\",\n",
    "    \"Americas\": \"http://rss.cnn.com/rss/edition_americas.rss\",\n",
    "    \"Asia\": \"http://rss.cnn.com/rss/edition_asia.rss\",\n",
    "    \"Europe\": \"http://rss.cnn.com/rss/edition_europe.rss\",\n",
    "    \"Middle East\": \"http://rss.cnn.com/rss/edition_meast.rss\",\n",
    "    \"U.S.\": \"http://rss.cnn.com/rss/edition_us.rss\",\n",
    "    \"Money\": \"http://rss.cnn.com/rss/money_news_international.rss\",\n",
    "    \"Technology\": \"http://rss.cnn.com/rss/edition_technology.rss\",\n",
    "    \"Science & Space\": \"http://rss.cnn.com/rss/edition_space.rss\",\n",
    "    \"Entertainment\":\"http://rss.cnn.com/rss/edition_entertainment.rss\",\n",
    "    \"World Sport\":\"http://rss.cnn.com/rss/edition_sport.rss\",\n",
    "    \"Football\" : \"http://rss.cnn.com/rss/edition_football.rss\",\n",
    "    \"Golf\": \"http://rss.cnn.com/rss/edition_golf.rss\",\n",
    "    \"Motorsport\": \"http://rss.cnn.com/rss/edition_motorsport.rss\",\n",
    "    \"Tennis\": \"http://rss.cnn.com/rss/edition_tennis.rss\",\n",
    "    \"Travel\":\"http://rss.cnn.com/rss/edition_travel.rss\",\n",
    "    \"Video\":\"http://rss.cnn.com/rss/cnn_freevideo.rss\",\n",
    "    \"Most Recent\":\"http://rss.cnn.com/rss/cnn_latest.rss\"}\n",
    "\n",
    "    def getSubtitle(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].summary_detail.value\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    def getPublished(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].published\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    def getMedia(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].media_content[0]['url']\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "\n",
    "    CNN_feed = pd.DataFrame()\n",
    "    for k in range(len(CNN_URLS)):\n",
    "        CNN_RSS = feedparser.parse(list(CNN_URLS.values())[k])\n",
    "        for i in range(len(CNN_RSS.entries)):\n",
    "            title = [CNN_RSS.entries[i].title for i in range(len(CNN_RSS.entries))]\n",
    "            subtitle = [ getSubtitle(i) for i in range(len(CNN_RSS.entries))]\n",
    "            url = [CNN_RSS.entries[i].links[0].href for i in range(len(CNN_RSS.entries))]\n",
    "            timestamp = [getPublished(i) for i in range(len(CNN_RSS.entries))]\n",
    "            original_image = [getMedia(i) for i in range(len(CNN_RSS.entries))]\n",
    "            section = [list(CNN_URLS.keys())[k] for i in range(len(CNN_RSS.entries))]\n",
    "            CNN_RSS_feed_p = pd.DataFrame([title, subtitle, url, timestamp, original_image]).transpose()\n",
    "            CNN_feed.append(CNN_RSS_feed_p, ignore_index=True)\n",
    "    \n",
    "    return CNN_feed\n",
    "    \n",
    "def FOX_parser():\n",
    "    FOX_URLS = {'Fox':\"https://www.foxnews.com/about/rss\"}\n",
    "\n",
    "def WSJ_parser():\n",
    "    #Proxys?? Da error 503, hay que ver como hacerle\n",
    "    WSJ_URLS = {\n",
    "    \"World\": \"https://feeds.a.dj.com/rss/RSSWorldNews.xml\",\n",
    "    \"Opinion\": \"https://feeds.a.dj.com/rss/RSSOpinion.xml\",\n",
    "    \"Business\":\"https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml\",\n",
    "    \"Markets\":\"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",\n",
    "    \"Technology\":\"https://feeds.a.dj.com/rss/RSSWSJD.xml\",\n",
    "    \"Lifestyle\":\"https://feeds.a.dj.com/rss/RSSLifestyle.xml\"}\n",
    "    \n",
    "def BBC_parser():\n",
    "    BBC_URLS = {\n",
    "    \"World\":\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "    \"UK\":\"http://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
    "    \"Business\":\"http://feeds.bbci.co.uk/news/business/rss.xml\",\n",
    "    \"Politics\": \"http://feeds.bbci.co.uk/news/politics/rss.xml\",\n",
    "    \"Health\": \"http://feeds.bbci.co.uk/news/health/rss.xml\",\n",
    "    \"Education\": \"http://feeds.bbci.co.uk/news/education/rss.xml\",\n",
    "    \"Science\": \"http://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
    "    \"Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
    "    \"Entretainment & Arts\": \"http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\"}\n",
    "\n",
    "    BBC_feed = pd.DataFrame()\n",
    "    for k in range(len(BBC_URLS)):\n",
    "        BBC_RSS = feedparser.parse(list(BBC_URLS.values())[k])\n",
    "        for i in range(len(BBC_RSS.entries)):\n",
    "            title = [BBC_RSS.entries[i].title for i in range(len(BBC_RSS.entries))]\n",
    "            subtitle = [ BBC_RSS.entries[i].summary for i in range(len(BBC_RSS.entries))]\n",
    "            url = [BBC_RSS.entries[i].links[0].href for i in range(len(BBC_RSS.entries))]\n",
    "            timestamp = [BBC_RSS.entries[0].published for i in range(len(BBC_RSS.entries))]\n",
    "            section = [list(BBC_RSS.keys())[k] for i in range(len(BBC_RSS.entries))]\n",
    "            BBC_RSS_feed_p = pd.DataFrame([title, subtitle, url, timestamp, section]).transpose()\n",
    "            BBC_feed.append(CNN_RSS_feed_p, ignore_index=True)\n",
    "    \n",
    "    return BBC_feed\n",
    "\n",
    "def USAT_parser():\n",
    "    \n",
    "    USAT_URLS = {\n",
    "    \"US\":\"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "    \"World\":\"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "    \"Opinion\":\"http://rssfeeds.usatoday.com/News-Opinion\",\n",
    "    \"Sports\":\"http://rssfeeds.usatoday.com/UsatodaycomSports-TopStories\",\n",
    "    \"Lifestyle\":\"http://rssfeeds.usatoday.com/usatoday-LifeTopStories\",\n",
    "    \"Money\":\"http://rssfeeds.usatoday.com/UsatodaycomMoney-TopStories\",\n",
    "    \"Tech\":\"http://rssfeeds.usatoday.com/usatoday-TechTopStories\",\n",
    "    \"Travel\":\"http://rssfeeds.usatoday.com/UsatodaycomTravel-TopStories\"}\n",
    "    \n",
    "    def getUSATMedia(i):\n",
    "        try: \n",
    "            return USAT_feed_p.entries[i].links[1].href\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    USAT_feed = []\n",
    "    for k in range(len(USAT_URLS)):\n",
    "        USAT_RSS = feedparser.parse(list(USAT_URLS.values())[k]).entries\n",
    "        for i in range(len(USAT_RSS)):\n",
    "            title =  [USAT_feed_p.entries[i].title for i in range(len(USAT_RSS))]\n",
    "            #summary = [re.findall('(?<=<p>).*(?=</p>)', USAT_feed_p.entries[i].content[0].value)[0]) for i in range(len(USAT_RSS))]\n",
    "            url = [USAT_feed_p.entries[i].feedburner_origlink for i in range(len(USAT_RSS))]\n",
    "            timestamp = [USAT_feed_p.entries[i].published for i in range(len(USAT_RSS))]\n",
    "            image = [getUSATMedia(i) for i in range(len(USAT_RSS))]\n",
    "            section = [list(USAT_URLS.keys())[k] for i in range(len(USAT_RSS))]\n",
    "            USAT_feed.append([title, summary, url, timestamp, image, section])\n",
    "    \n",
    "    return USAT_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS = feedparser.parse(\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS.entries[0].media_content[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_feed = []\n",
    "def getNYTMedia(i):\n",
    "    try: \n",
    "        return media == NYT_RSS.entries[i].media_content[0]['url']\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "    \n",
    "for k in range(len(NYT_URLS)):\n",
    "    NYT_RSS = feedparser.parse(list(NYT_URLS.values())[k]).entries\n",
    "    for i in range(len(NYT_RSS)):\n",
    "        title = [NYT_RSS.entries[i].title for i in range(len(NYT_RSS))]\n",
    "        url = [NYT_RSS.entries[i].link for i in range(len(NYT_RSS))]\n",
    "        summary = [NYT_RSS.entries[i].summary for i in range(len(NYT_RSS))]\n",
    "        timestamp = [NYT_RSS.entries[i].published for i in range(len(NYT_RSS))]\n",
    "        media = [getNYTMedia(i) for i in range(len(NYT_RSS))]\n",
    "        section = [list(NYT_URLS.keys())[k] for i in range(len(NYT_RSS))]\n",
    "        NYT_feed.append([title, summary, url, timestamp, media, section])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_URLS = {\n",
    "    \"World\":\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "    \"Africa\":\n",
    "    \"Americas\":\n",
    "    \"Asia Pacific\":\n",
    "    \"Europe\":\n",
    "    \"Middle East\":\n",
    "    \"US\":\n",
    "    \"Education\":\n",
    "    \"Politics\":\"https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml\"\n",
    "    \"Business\":\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\",\n",
    "    \"Technology\":\"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
    "    \"Sports\":\"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
