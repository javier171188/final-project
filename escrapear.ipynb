{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feedparser\n",
    "#!pip install beautifulsoup4\n",
    "#!pip install bs4\n",
    "#!pip install lxml\n",
    "#!pip install pandas\n",
    "#!pip install umap\n",
    "#!pip install 'umap-learn==0.3.10'\n",
    "#!pip install requests\n",
    "#!pip install nltk\n",
    "#!pip install umap\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('venv/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "#import umap.umap_ as UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpieza\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = feedparser.parse('http://rss.cnn.com/rss/edition.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_parser():\n",
    "    CNN_list=[]\n",
    "    CNN_URLS = {\n",
    "    \"Top Stories\": \"http://rss.cnn.com/rss/edition.rss\",\n",
    "    \"World\": \"http://rss.cnn.com/rss/edition_world.rss\",\n",
    "    \"Africa\": \"http://rss.cnn.com/rss/edition_africa.rss\",\n",
    "    \"Americas\": \"http://rss.cnn.com/rss/edition_americas.rss\",\n",
    "    \"Asia\": \"http://rss.cnn.com/rss/edition_asia.rss\",\n",
    "    \"Europe\": \"http://rss.cnn.com/rss/edition_europe.rss\",\n",
    "    \"Middle East\": \"http://rss.cnn.com/rss/edition_meast.rss\",\n",
    "    \"U.S.\": \"http://rss.cnn.com/rss/edition_us.rss\",\n",
    "    \"Money\": \"http://rss.cnn.com/rss/money_news_international.rss\",\n",
    "    \"Technology\": \"http://rss.cnn.com/rss/edition_technology.rss\",\n",
    "    \"Science & Space\": \"http://rss.cnn.com/rss/edition_space.rss\",\n",
    "    \"Entertainment\":\"http://rss.cnn.com/rss/edition_entertainment.rss\",\n",
    "    \"World Sport\":\"http://rss.cnn.com/rss/edition_sport.rss\",\n",
    "    \"Football\" : \"http://rss.cnn.com/rss/edition_football.rss\",\n",
    "    \"Golf\": \"http://rss.cnn.com/rss/edition_golf.rss\",\n",
    "    \"Motorsport\": \"http://rss.cnn.com/rss/edition_motorsport.rss\",\n",
    "    \"Tennis\": \"http://rss.cnn.com/rss/edition_tennis.rss\",\n",
    "    \"Travel\":\"http://rss.cnn.com/rss/edition_travel.rss\",\n",
    "    \"Video\":\"http://rss.cnn.com/rss/cnn_freevideo.rss\",\n",
    "    \"Most Recent\":\"http://rss.cnn.com/rss/cnn_latest.rss\"}\n",
    "    for e in CNN_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(CNN_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            CNN_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return CNN_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_list = CNN_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOX_parser():\n",
    "    FOX_list = []\n",
    "    FOX_URLS = {'Fox':\"https://www.foxnews.com/about/rss\"}\n",
    "    \n",
    "    \n",
    "    for e in FOX_URLS:\n",
    "        if hasattr(ssl, '_create_unverified_context'):\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(FOX_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            FOX_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return FOX_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOX_list=FOX_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOX_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WSJ_parser():\n",
    "    WSJ_list=[]\n",
    "    WSJ_URLS = {\n",
    "    \"World\": \"https://feeds.a.dj.com/rss/RSSWorldNews.xml\",\n",
    "    \"Opinion\": \"https://feeds.a.dj.com/rss/RSSOpinion.xml\",\n",
    "    \"Business\":\"https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml\",\n",
    "    \"Markets\":\"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",\n",
    "    \"Technology\":\"https://feeds.a.dj.com/rss/RSSWSJD.xml\",\n",
    "    \"Lifestyle\":\"https://feeds.a.dj.com/rss/RSSLifestyle.xml\"}\n",
    "    for e in WSJ_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(WSJ_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            WSJ_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return WSJ_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_list = WSJ_parser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBC_parser():\n",
    "    BBC_list=[]\n",
    "    BBC_URLS = {\n",
    "    \"World\":\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "    \"UK\":\"http://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
    "    \"Business\":\"http://feeds.bbci.co.uk/news/business/rss.xml\",\n",
    "    \"Politics\": \"http://feeds.bbci.co.uk/news/politics/rss.xml\",\n",
    "    \"Health\": \"http://feeds.bbci.co.uk/news/health/rss.xml\",\n",
    "    \"Education\": \"http://feeds.bbci.co.uk/news/education/rss.xml\",\n",
    "    \"Science\": \"http://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
    "    \"Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
    "    \"Entretainment & Arts\": \"http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\"}\n",
    "    for e in BBC_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(BBC_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            BBC_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return BBC_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_list = BBC_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def USAT_parser():\n",
    "    USAT_list=[]\n",
    "    USAT_URLS = {\n",
    "    \"US\":\"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "    \"World\":\"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "    \"Opinion\":\"http://rssfeeds.usatoday.com/News-Opinion\",\n",
    "    \"Sports\":\"http://rssfeeds.usatoday.com/UsatodaycomSports-TopStories\",\n",
    "    \"Lifestyle\":\"http://rssfeeds.usatoday.com/usatoday-LifeTopStories\",\n",
    "    \"Money\":\"http://rssfeeds.usatoday.com/UsatodaycomMoney-TopStories\",\n",
    "    \"Tech\":\"http://rssfeeds.usatoday.com/usatoday-TechTopStories\",\n",
    "    \"Travel\":\"http://rssfeeds.usatoday.com/UsatodaycomTravel-TopStories\"}\n",
    "    for e in USAT_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(USAT_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            USAT_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return USAT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAT_list = USAT_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NYT_parser():\n",
    "    NYT_list=[]\n",
    "    NYT_URLS = {\n",
    "    \"World\":\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "    \"Politics\":\"https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml\",\n",
    "    \"Business\":\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\",\n",
    "    \"Technology\":\"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
    "    \"Sports\":\"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\"}\n",
    "    \n",
    "    for e in NYT_URLS:\n",
    "        #print('\\n La sección es: '+e+ '\\n')\n",
    "        temp = feedparser.parse(NYT_URLS[e])\n",
    "        for i in range(len(temp['entries'])):\n",
    "            #print(temp['entries'][i]['title'])\n",
    "            NYT_list.append(temp['entries'][i]['title'])\n",
    "            \n",
    "        \n",
    "    #print(temp.keys)\n",
    "    return NYT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_list =NYT_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "News = CNN_list + FOX_list+WSJ_list+BBC_list+USAT_list+NYT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf = pd.DataFrame(News, columns = ['Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump publicly minimizes impeachment but priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graham pokes holes in FBI's Russia investigati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lemon mocks Trump team's troll: Are you people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tourists describe 'horrific' aftermath of erup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India passes controversial citizenship bill th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles\n",
       "0  Trump publicly minimizes impeachment but priva...\n",
       "1  Graham pokes holes in FBI's Russia investigati...\n",
       "2  Lemon mocks Trump team's troll: Are you people...\n",
       "3  Tourists describe 'horrific' aftermath of erup...\n",
       "4  India passes controversial citizenship bill th..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(s):\n",
    "    n = analyzer.polarity_scores(s)['neg']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Negative'] = Newsdf['Titles'].apply(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neut(s):\n",
    "    n = analyzer.polarity_scores(s)['neg']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Neutral'] = Newsdf['Titles'].apply(neut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(s):\n",
    "    n = analyzer.polarity_scores(s)['pos']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['Positive'] = Newsdf['Titles'].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com(s):\n",
    "    n = analyzer.polarity_scores(s)['compound']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['compound'] = Newsdf['Titles'].apply(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Newsdf['token'] = Newsdf['Titles'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=English()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    tokens=parser(sentence)\n",
    "    \n",
    "    filtered_tokens=[]\n",
    "    for word in tokens:\n",
    "        lemma=word.lemma_.lower().strip()\n",
    "        #print (word, lemma)\n",
    "        if lemma not in STOP_WORDS and re.search('^[a-zA-Z]+$', lemma):\n",
    "            filtered_tokens.append(lemma)\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix=tfidf.fit_transform(Newsdf['Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=tfidf.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=1-cosine_similarity(tfidf_matrix)\n",
    "#prueba = dist[0:98,0:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan=HDBSCAN()\n",
    "clusters=hdbscan.fit_predict(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newsdf['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump publicly minimizes impeachment but priva...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graham pokes holes in FBI's Russia investigati...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lemon mocks Trump team's troll: Are you people...</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tourists describe 'horrific' aftermath of erup...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India passes controversial citizenship bill th...</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>Some N.B.A. Draft-Night Snubs Are Turning Into...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>The Knicks Can’t Fix It</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Eli Manning Returns but Giants Lose to Eagles</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5499</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Marvin Miller Adds a Missing Piece of Baseball...</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>At Nike, Employees March to Protest Support fo...</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1353 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titles  Negative  Neutral  \\\n",
       "0     Trump publicly minimizes impeachment but priva...     0.000    0.000   \n",
       "1     Graham pokes holes in FBI's Russia investigati...     0.000    0.000   \n",
       "2     Lemon mocks Trump team's troll: Are you people...     0.449    0.449   \n",
       "3     Tourists describe 'horrific' aftermath of erup...     0.000    0.000   \n",
       "4     India passes controversial citizenship bill th...     0.205    0.205   \n",
       "...                                                 ...       ...      ...   \n",
       "1348  Some N.B.A. Draft-Night Snubs Are Turning Into...     0.307    0.307   \n",
       "1349                            The Knicks Can’t Fix It     0.000    0.000   \n",
       "1350      Eli Manning Returns but Giants Lose to Eagles     0.336    0.336   \n",
       "1351  Marvin Miller Adds a Missing Piece of Baseball...     0.137    0.137   \n",
       "1352  At Nike, Employees March to Protest Support fo...     0.157    0.157   \n",
       "\n",
       "      Positive  compound  clusters  \n",
       "0        0.000    0.0000        -1  \n",
       "1        0.000    0.0000        -1  \n",
       "2        0.000   -0.6908        -1  \n",
       "3        0.211    0.4939        -1  \n",
       "4        0.000   -0.2023         4  \n",
       "...        ...       ...       ...  \n",
       "1348     0.000   -0.4767        -1  \n",
       "1349     0.000    0.0000        -1  \n",
       "1350     0.000   -0.5499        -1  \n",
       "1351     0.180    0.1779        -1  \n",
       "1352     0.213    0.1779        -1  \n",
       "\n",
       "[1353 rows x 6 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abiy</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abortions</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abu</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimbabweans</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "      <th>zozo</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaliyah  abandoned  abdul  abiy  able  aboard  abortions  absolutely  abu  \\\n",
       "0      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0  0.0   \n",
       "1      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0  0.0   \n",
       "2      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0  0.0   \n",
       "3      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0  0.0   \n",
       "4      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0  0.0   \n",
       "\n",
       "   abuse  ...  zealand  zelensky  zimbabwe  zimbabweans  zombie  zone  zoo  \\\n",
       "0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0  0.0   \n",
       "1    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0  0.0   \n",
       "2    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0  0.0   \n",
       "3    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0  0.0   \n",
       "4    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0  0.0   \n",
       "\n",
       "   zoos  zozo  zuckerberg  \n",
       "0   0.0   0.0         0.0  \n",
       "1   0.0   0.0         0.0  \n",
       "2   0.0   0.0         0.0  \n",
       "3   0.0   0.0         0.0  \n",
       "4   0.0   0.0         0.0  \n",
       "\n",
       "[5 rows x 3879 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(), columns=terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abiy</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abortions</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abu</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimbabweans</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "      <th>zozo</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaliyah  abandoned  abdul  abiy  able  aboard  abortions  absolutely  \\\n",
       "42        0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "292       0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "391       0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "879       0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "917       0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "984       0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "1069      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "1070      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "1071      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "1130      0.0        0.0    0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "\n",
       "      abu  abuse  ...  zealand  zelensky  zimbabwe  zimbabweans  zombie  zone  \\\n",
       "42    0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "292   0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "391   0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "879   0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "917   0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "984   0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "1069  0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "1070  0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "1071  0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "1130  0.0    0.0  ...      0.0       0.0       0.0          0.0     0.0   0.0   \n",
       "\n",
       "      zoo  zoos  zozo  zuckerberg  \n",
       "42    0.0   0.0   0.0         0.0  \n",
       "292   0.0   0.0   0.0         0.0  \n",
       "391   0.0   0.0   0.0         0.0  \n",
       "879   0.0   0.0   0.0         0.0  \n",
       "917   0.0   0.0   0.0         0.0  \n",
       "984   0.0   0.0   0.0         0.0  \n",
       "1069  0.0   0.0   0.0         0.0  \n",
       "1070  0.0   0.0   0.0         0.0  \n",
       "1071  0.0   0.0   0.0         0.0  \n",
       "1130  0.0   0.0   0.0         0.0  \n",
       "\n",
       "[10 rows x 3879 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df[clusters==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zealand     5.478100\n",
       "volcano     4.371392\n",
       "new         4.123852\n",
       "eruption    3.646012\n",
       "island      2.073555\n",
       "rescue      1.434834\n",
       "tourists    1.253926\n",
       "volcanic    1.246167\n",
       "white       1.057052\n",
       "survived    0.940739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_cluster=tfidf_df[clusters==8].T.sum(axis=1).sort_values(ascending=False)\n",
    "top_words_cluster.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice = top_words_cluster.keys()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zealand"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(practice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-3ba7ca468fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpractice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mnouns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "adjectives = []\n",
    "for token in practice:\n",
    "    pass\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == 'ADJ':\n",
    "        adjectives.append(token)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[6, 9, 12]\n",
      "We\n",
      "the geometry of the edges of the images\n",
      "We\n",
      "geometry\n",
      "the edges of the images\n",
      "We\n",
      "geometry\n",
      "edges\n",
      "the images\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"We try to explicitly describe the geometry of the edges of the images.\")\n",
    "\n",
    "for np in doc.noun_chunks: # use np instead of np.text\n",
    "    #print(np)\n",
    "    pass\n",
    "\n",
    "print()\n",
    "\n",
    "# code to recursively combine nouns\n",
    "# 'We' is actually a pronoun but included in your question\n",
    "# hence the token.pos_ == \"PRON\" part in the last if statement\n",
    "# suggest you extract PRON separately like the noun-chunks above\n",
    "\n",
    "index = 0\n",
    "nounIndices = []\n",
    "for token in doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nounIndices.append(index)\n",
    "        print()\n",
    "    index = index + 1\n",
    "\n",
    "\n",
    "print(nounIndices)\n",
    "for idxValue in nounIndices:\n",
    "    doc = nlp(\"We try to explicitly describe the geometry of the edges of the images.\")\n",
    "    span = doc[doc[idxValue].left_edge.i : doc[idxValue].right_edge.i+1]\n",
    "    span.merge()\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj' or token.dep_ == 'pobj' or token.pos_ == \"PRON\":\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####De aquí para abajo es el código de uaqro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_parser():\n",
    "    CNN_URLS = {\n",
    "    \"Top Stories\": \"http://rss.cnn.com/rss/edition.rss\",\n",
    "    \"World\": \"http://rss.cnn.com/rss/edition_world.rss\",\n",
    "    \"Africa\": \"http://rss.cnn.com/rss/edition_africa.rss\",\n",
    "    \"Americas\": \"http://rss.cnn.com/rss/edition_americas.rss\",\n",
    "    \"Asia\": \"http://rss.cnn.com/rss/edition_asia.rss\",\n",
    "    \"Europe\": \"http://rss.cnn.com/rss/edition_europe.rss\",\n",
    "    \"Middle East\": \"http://rss.cnn.com/rss/edition_meast.rss\",\n",
    "    \"U.S.\": \"http://rss.cnn.com/rss/edition_us.rss\",\n",
    "    \"Money\": \"http://rss.cnn.com/rss/money_news_international.rss\",\n",
    "    \"Technology\": \"http://rss.cnn.com/rss/edition_technology.rss\",\n",
    "    \"Science & Space\": \"http://rss.cnn.com/rss/edition_space.rss\",\n",
    "    \"Entertainment\":\"http://rss.cnn.com/rss/edition_entertainment.rss\",\n",
    "    \"World Sport\":\"http://rss.cnn.com/rss/edition_sport.rss\",\n",
    "    \"Football\" : \"http://rss.cnn.com/rss/edition_football.rss\",\n",
    "    \"Golf\": \"http://rss.cnn.com/rss/edition_golf.rss\",\n",
    "    \"Motorsport\": \"http://rss.cnn.com/rss/edition_motorsport.rss\",\n",
    "    \"Tennis\": \"http://rss.cnn.com/rss/edition_tennis.rss\",\n",
    "    \"Travel\":\"http://rss.cnn.com/rss/edition_travel.rss\",\n",
    "    \"Video\":\"http://rss.cnn.com/rss/cnn_freevideo.rss\",\n",
    "    \"Most Recent\":\"http://rss.cnn.com/rss/cnn_latest.rss\"}\n",
    "\n",
    "    def getSubtitle(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].summary_detail.value\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    def getPublished(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].published\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    def getMedia(i):\n",
    "        try: \n",
    "            return CNN_RSS.entries[i].media_content[0]['url']\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "\n",
    "    CNN_feed = pd.DataFrame()\n",
    "    for k in range(len(CNN_URLS)):\n",
    "        CNN_RSS = feedparser.parse(list(CNN_URLS.values())[k])\n",
    "        for i in range(len(CNN_RSS.entries)):\n",
    "            title = [CNN_RSS.entries[i].title for i in range(len(CNN_RSS.entries))]\n",
    "            subtitle = [ getSubtitle(i) for i in range(len(CNN_RSS.entries))]\n",
    "            url = [CNN_RSS.entries[i].links[0].href for i in range(len(CNN_RSS.entries))]\n",
    "            timestamp = [getPublished(i) for i in range(len(CNN_RSS.entries))]\n",
    "            original_image = [getMedia(i) for i in range(len(CNN_RSS.entries))]\n",
    "            section = [list(CNN_URLS.keys())[k] for i in range(len(CNN_RSS.entries))]\n",
    "            CNN_RSS_feed_p = pd.DataFrame([title, subtitle, url, timestamp, original_image]).transpose()\n",
    "            CNN_feed.append(CNN_RSS_feed_p, ignore_index=True)\n",
    "    \n",
    "    return CNN_feed\n",
    "    \n",
    "def FOX_parser():\n",
    "    FOX_URLS = {'Fox':\"https://www.foxnews.com/about/rss\"}\n",
    "\n",
    "def WSJ_parser():\n",
    "    #Proxys?? Da error 503, hay que ver como hacerle\n",
    "    WSJ_URLS = {\n",
    "    \"World\": \"https://feeds.a.dj.com/rss/RSSWorldNews.xml\",\n",
    "    \"Opinion\": \"https://feeds.a.dj.com/rss/RSSOpinion.xml\",\n",
    "    \"Business\":\"https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml\",\n",
    "    \"Markets\":\"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",\n",
    "    \"Technology\":\"https://feeds.a.dj.com/rss/RSSWSJD.xml\",\n",
    "    \"Lifestyle\":\"https://feeds.a.dj.com/rss/RSSLifestyle.xml\"}\n",
    "    \n",
    "def BBC_parser():\n",
    "    BBC_URLS = {\n",
    "    \"World\":\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "    \"UK\":\"http://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
    "    \"Business\":\"http://feeds.bbci.co.uk/news/business/rss.xml\",\n",
    "    \"Politics\": \"http://feeds.bbci.co.uk/news/politics/rss.xml\",\n",
    "    \"Health\": \"http://feeds.bbci.co.uk/news/health/rss.xml\",\n",
    "    \"Education\": \"http://feeds.bbci.co.uk/news/education/rss.xml\",\n",
    "    \"Science\": \"http://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
    "    \"Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
    "    \"Entretainment & Arts\": \"http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\"}\n",
    "\n",
    "    BBC_feed = pd.DataFrame()\n",
    "    for k in range(len(BBC_URLS)):\n",
    "        BBC_RSS = feedparser.parse(list(BBC_URLS.values())[k])\n",
    "        for i in range(len(BBC_RSS.entries)):\n",
    "            title = [BBC_RSS.entries[i].title for i in range(len(BBC_RSS.entries))]\n",
    "            subtitle = [ BBC_RSS.entries[i].summary for i in range(len(BBC_RSS.entries))]\n",
    "            url = [BBC_RSS.entries[i].links[0].href for i in range(len(BBC_RSS.entries))]\n",
    "            timestamp = [BBC_RSS.entries[0].published for i in range(len(BBC_RSS.entries))]\n",
    "            section = [list(BBC_RSS.keys())[k] for i in range(len(BBC_RSS.entries))]\n",
    "            BBC_RSS_feed_p = pd.DataFrame([title, subtitle, url, timestamp, section]).transpose()\n",
    "            BBC_feed.append(CNN_RSS_feed_p, ignore_index=True)\n",
    "    \n",
    "    return BBC_feed\n",
    "\n",
    "def USAT_parser():\n",
    "    \n",
    "    USAT_URLS = {\n",
    "    \"US\":\"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "    \"World\":\"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "    \"Opinion\":\"http://rssfeeds.usatoday.com/News-Opinion\",\n",
    "    \"Sports\":\"http://rssfeeds.usatoday.com/UsatodaycomSports-TopStories\",\n",
    "    \"Lifestyle\":\"http://rssfeeds.usatoday.com/usatoday-LifeTopStories\",\n",
    "    \"Money\":\"http://rssfeeds.usatoday.com/UsatodaycomMoney-TopStories\",\n",
    "    \"Tech\":\"http://rssfeeds.usatoday.com/usatoday-TechTopStories\",\n",
    "    \"Travel\":\"http://rssfeeds.usatoday.com/UsatodaycomTravel-TopStories\"}\n",
    "    \n",
    "    def getUSATMedia(i):\n",
    "        try: \n",
    "            return USAT_feed_p.entries[i].links[1].href\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "    USAT_feed = []\n",
    "    for k in range(len(USAT_URLS)):\n",
    "        USAT_RSS = feedparser.parse(list(USAT_URLS.values())[k]).entries\n",
    "        for i in range(len(USAT_RSS)):\n",
    "            title =  [USAT_feed_p.entries[i].title for i in range(len(USAT_RSS))]\n",
    "            #summary = [re.findall('(?<=<p>).*(?=</p>)', USAT_feed_p.entries[i].content[0].value)[0]) for i in range(len(USAT_RSS))]\n",
    "            url = [USAT_feed_p.entries[i].feedburner_origlink for i in range(len(USAT_RSS))]\n",
    "            timestamp = [USAT_feed_p.entries[i].published for i in range(len(USAT_RSS))]\n",
    "            image = [getUSATMedia(i) for i in range(len(USAT_RSS))]\n",
    "            section = [list(USAT_URLS.keys())[k] for i in range(len(USAT_RSS))]\n",
    "            USAT_feed.append([title, summary, url, timestamp, image, section])\n",
    "    \n",
    "    return USAT_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS = feedparser.parse(\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS.entries[0].media_content[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_RSS.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_feed = []\n",
    "def getNYTMedia(i):\n",
    "    try: \n",
    "        return media == NYT_RSS.entries[i].media_content[0]['url']\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "    \n",
    "for k in range(len(NYT_URLS)):\n",
    "    NYT_RSS = feedparser.parse(list(NYT_URLS.values())[k]).entries\n",
    "    for i in range(len(NYT_RSS)):\n",
    "        title = [NYT_RSS.entries[i].title for i in range(len(NYT_RSS))]\n",
    "        url = [NYT_RSS.entries[i].link for i in range(len(NYT_RSS))]\n",
    "        summary = [NYT_RSS.entries[i].summary for i in range(len(NYT_RSS))]\n",
    "        timestamp = [NYT_RSS.entries[i].published for i in range(len(NYT_RSS))]\n",
    "        media = [getNYTMedia(i) for i in range(len(NYT_RSS))]\n",
    "        section = [list(NYT_URLS.keys())[k] for i in range(len(NYT_RSS))]\n",
    "        NYT_feed.append([title, summary, url, timestamp, media, section])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_URLS = {\n",
    "    \"World\":\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "    \"Africa\":\n",
    "    \"Americas\":\n",
    "    \"Asia Pacific\":\n",
    "    \"Europe\":\n",
    "    \"Middle East\":\n",
    "    \"US\":\n",
    "    \"Education\":\n",
    "    \"Politics\":\"https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml\"\n",
    "    \"Business\":\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\",\n",
    "    \"Technology\":\"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
    "    \"Sports\":\"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
